# Grok AI Companion PoC â€“ Web Spec (Next.js + FastAPI)

## 0. ëª©í‘œ ì •ë¦¬ (Epic ì—°ê²°)

- **Epic 1 (ì™„ë£Œ)**: PoC ê¸°íš ë° í˜ë¥´ì†Œë‚˜ ì •ì˜  
- **Epic 2 (ê±°ì˜ ì™„ë£Œ)**: Veo2 ì—ì…‹ 3Ã—2ì¢…(ê¸°ë³¸/ê¸°ì¨/ìŠ¬í”” Ã— idle/ë§í•˜ê¸°) ì œì‘  
- **ì§€ê¸ˆ ëª©í‘œ**
  - ì›¹ì—ì„œ ëŒì•„ê°€ëŠ” **AI Companion PoC**ë¥¼ ë§Œë“ ë‹¤.
  - **í”„ë¡ íŠ¸**: ì˜ìƒ(ìƒíƒœë³„ Veo2 í´ë¦½) + í…ìŠ¤íŠ¸/ìŒì„± ì±„íŒ… UI
  - **ë°±ì—”ë“œ**: Gemini ì—°ë™, ìƒíƒœ ê²°ì • ë¡œì§, STT/TTS ì—°ë™

---

## 1. ì „ì²´ ì•„í‚¤í…ì²˜

### 1.1 êµ¬ì„±

- **frontend/** â†’ Next.js(React, TypeScript, App Router)
- **backend/** â†’ FastAPI (Python 3.11+)

ë¸Œë¼ìš°ì €  
â†’ `Next.js` (ì±„íŒ… UI + Veo2 ì˜ìƒ í”Œë ˆì´ì–´)  
â†’ (HTTP / fetch)  
â†’ `FastAPI` (Gemini, STT, TTS, ìƒíƒœ ë¨¸ì‹ )  
â†’ ì™¸ë¶€ APIë“¤ (Gemini, STT/TTS, Veo2 ìƒì„±ì€ ì´ë¯¸ ì™„ë£Œëœ íŒŒì¼ ì‚¬ìš©)

---

## 2. í”„ë¡ íŠ¸ì—”ë“œ ìŠ¤í™ (Next.js)

### 2.1 Tech Stack

- **Next.js 14+ (App Router)**
- **TypeScript**
- **TailwindCSS** (ë¹ ë¥¸ UI êµ¬ì„±)
- ìƒíƒœê´€ë¦¬: **React Query** + ì»´í¬ë„ŒíŠ¸ ë‚´ë¶€ state ì •ë„ë¡œ ì¶©ë¶„
- ë¹„ë””ì˜¤: `<video>` íƒœê·¸ ë˜ëŠ” React Player (í•„ìš” ì‹œ)

### 2.2 í´ë” êµ¬ì¡° (ì œì•ˆ)

```bash
frontend/
  app/
    layout.tsx
    page.tsx                 # ë©”ì¸ Companion í™”ë©´
    api/                     # (ì„ íƒ) Next API Route, í˜„ì¬ëŠ” FastAPI ì‚¬ìš©ì´ ë©”ì¸
  src/
    components/
      ChatPanel.tsx          # í…ìŠ¤íŠ¸ ì±„íŒ… UI
      VideoAvatar.tsx        # Veo2 ìºë¦­í„° ì˜ìƒ ì»´í¬ë„ŒíŠ¸
      MessageBubble.tsx      # ì±„íŒ… ë§í’ì„ 
      MicButton.tsx          # STT íŠ¸ë¦¬ê±° ë²„íŠ¼
      AudioPlayer.tsx        # TTS ì¬ìƒ ì»´í¬ë„ŒíŠ¸
    hooks/
      useChat.ts             # ì±„íŒ… / ìƒíƒœ ì „í™˜ ë¡œì§ í›…
    lib/
      apiClient.ts           # FastAPI í˜¸ì¶œ í´ë¼ì´ì–¸íŠ¸
      emotionMapping.ts      # ìƒíƒœâ†’ì˜ìƒ URL ë§¤í•‘
      types.ts               # ê³µí†µ íƒ€ì… ì •ì˜
    styles/
      globals.css
  package.json
  tsconfig.json
  tailwind.config.js
2.3 ìƒíƒœ/ì˜ìƒ ë§¤í•‘ ì •ì˜
ìƒíƒœ ì •ì˜

base_idle

base_talking

happy_idle

happy_talking

sad_idle

sad_talking

ë˜ëŠ”

emotion = "base" | "happy" | "sad"

mode = "idle" | "talking"

ì˜ˆì‹œ â€“ src/lib/emotionMapping.ts

ts
ì½”ë“œ ë³µì‚¬
export type Emotion = 'base' | 'happy' | 'sad';
export type Mode = 'idle' | 'talking';

export type VideoState = {
  emotion: Emotion;
  mode: Mode;
};

export const VIDEO_SOURCES: Record<Emotion, Record<Mode, string>> = {
  base: {
    idle: '/videos/base_idle.mp4',
    talking: '/videos/base_talking.mp4',
  },
  happy: {
    idle: '/videos/happy_idle.mp4',
    talking: '/videos/happy_talking.mp4',
  },
  sad: {
    idle: '/videos/sad_idle.mp4',
    talking: '/videos/sad_talking.mp4',
  },
};
2.4 ì£¼ìš” ì»´í¬ë„ŒíŠ¸ ì„¤ëª…
2.4.1 <VideoAvatar />
props:

emotion: Emotion

mode: Mode

isSpeaking: boolean (TTS ì¬ìƒ ì¤‘ ì—¬ë¶€)

ì—­í• :

VIDEO_SOURCES[emotion][mode]ë¡œ ë¹„ë””ì˜¤ src ì„ íƒ

autoPlay, loop, muted ì„¤ì •

ë§í•˜ëŠ” ìƒíƒœì¼ ë• mode = 'talking' ì‚¬ìš©, ì•„ë‹ ë• 'idle'

tsx
ì½”ë“œ ë³µì‚¬
// src/components/VideoAvatar.tsx
import { Emotion, Mode, VIDEO_SOURCES } from '@/lib/emotionMapping';

type Props = {
  emotion: Emotion;
  mode: Mode;
};

export function VideoAvatar({ emotion, mode }: Props) {
  const src = VIDEO_SOURCES[emotion][mode];

  return (
    <div className="w-full max-w-md mx-auto aspect-video rounded-xl overflow-hidden bg-black">
      <video
        src={src}
        autoPlay
        loop
        muted
        playsInline
        className="w-full h-full object-cover"
      />
    </div>
  );
}
2.4.2 <ChatPanel />
ìœ ì € í…ìŠ¤íŠ¸ ì…ë ¥

ì´ì „ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ë Œë”

useChat í›…ì„ ì‚¬ìš©í•´ FastAPI /chat í˜¸ì¶œ

ì‘ë‹µ ë°›ìœ¼ë©´:

ë©”ì‹œì§€ ëª©ë¡ ì—…ë°ì´íŠ¸

emotion, modeì— ë”°ë¼ ìƒë‹¨ VideoAvatar ìƒíƒœ ê°±ì‹ 

TTS URL ìˆìœ¼ë©´ <AudioPlayer>ë¡œ ì¬ìƒ

2.4.3 useChat í›…
ë‚´ë¶€ state:

messages: ChatMessage[]

videoState: { emotion: Emotion; mode: Mode }

isLoading

ë©”ì„œë“œ:

sendTextMessage(text: string)

ë‚˜ì¤‘ì— sendVoiceMessage(blob: Blob)ë„ ì¶”ê°€(STT)

3. ë°±ì—”ë“œ ìŠ¤í™ (FastAPI)
3.1 Tech Stack
Python 3.11+

FastAPI

uvicorn

HTTP í´ë¼ì´ì–¸íŠ¸: httpx í˜¹ì€ requests

TTS/STTëŠ” ë‚˜ì¤‘ì— ì‹¤ì œ ì„œë¹„ìŠ¤ ë¶™ì¼ ìˆ˜ ìˆë„ë¡ ì¶”ìƒí™” ë ˆì´ì–´ë¡œ ì„¤ê³„

3.2 í´ë” êµ¬ì¡° (ì œì•ˆ)
bash
ì½”ë“œ ë³µì‚¬
backend/
  app/
    main.py
    api/
      __init__.py
      chat.py         # /chat ì—”ë“œí¬ì¸íŠ¸
      stt.py          # /stt (ì„ íƒ)
      tts.py          # /tts (ì„ íƒ)
    core/
      config.py       # í™˜ê²½ë³€ìˆ˜, ì„¤ì •
      state_machine.py# í…ìŠ¤íŠ¸ â†’ ê°ì •/ìƒíƒœ ê²°ì • ë¡œì§
      gemini_client.py# Gemini í˜¸ì¶œ ë˜í¼
      tts_client.py   # TTS ë˜í¼
      stt_client.py   # STT ë˜í¼
    models/
      __init__.py
      chat.py         # Pydantic ëª¨ë¸
  requirements.txt
3.3 í™˜ê²½ë³€ìˆ˜ (ì˜ˆì‹œ)
GEMINI_API_KEY

TTS_API_KEY (ì„ íƒ)

STT_API_KEY (ì„ íƒ)

ALLOWED_ORIGINS (CORS)

3.4 ì£¼ìš” ì—”ë“œí¬ì¸íŠ¸ ì„¤ê³„
3.4.1 POST /api/chat
ìš”ì²­(Request)

json
ì½”ë“œ ë³µì‚¬
{
  "session_id": "optional-session-id",
  "user_message": "string",
  "current_emotion": "base | happy | sad",
  "current_mode": "idle | talking"
}
ì‘ë‹µ(Response)

json
ì½”ë“œ ë³µì‚¬
{
  "reply": "AIì˜ í…ìŠ¤íŠ¸ ì‘ë‹µ",
  "emotion": "base | happy | sad",
  "mode": "idle | talking",
  "tts_audio_url": "https://.../audio/file.mp3",
  "debug": {
    "gemini_raw": {},
    "state_reason": "ì™œ ì´ ê°ì •/ìƒíƒœê°€ ê²°ì •ë˜ì—ˆëŠ”ì§€ ê°„ë‹¨ ì„¤ëª…"
  }
}
ê¸°ë³¸ PoCì—ì„œëŠ” tts_audio_url ì—†ì´ í…ìŠ¤íŠ¸ë§Œ ë¦¬í„´í•´ë„ OK.

ë‚˜ì¤‘ì— TTS ë¶™ì´ë©´ URL ë¦¬í„´.

FastAPI ì˜ˆì‹œ ìŠ¤ì¼ˆë ˆí†¤ â€“ app/api/chat.py

python
ì½”ë“œ ë³µì‚¬
from fastapi import APIRouter
from pydantic import BaseModel
from app.core.state_machine import decide_state
from app.core.gemini_client import call_gemini

router = APIRouter()

class ChatRequest(BaseModel):
    session_id: str | None = None
    user_message: str
    current_emotion: str = "base"
    current_mode: str = "idle"

class ChatResponse(BaseModel):
    reply: str
    emotion: str
    mode: str
    tts_audio_url: str | None = None
    debug: dict | None = None


@router.post("/chat", response_model=ChatResponse)
async def chat(req: ChatRequest):
    # 1) Geminiì— ìœ ì € ë©”ì‹œì§€ ì „ë‹¬
    gemini_reply = await call_gemini(req.user_message)

    # 2) ìƒíƒœ ê²°ì • ë¡œì§ (í‚¤ì›Œë“œ ê¸°ë°˜ ê°„ë‹¨ ë£° â†’ ë‚˜ì¤‘ì— ê³ ë„í™”)
    emotion, mode, reason = decide_state(
        user_message=req.user_message,
        model_reply=gemini_reply,
        current_emotion=req.current_emotion,
    )

    # 3) (ì„ íƒ) TTS í˜¸ì¶œ í›„ URL ë°˜í™˜
    tts_url = None
    # tts_url = await synthesize_tts(gemini_reply)

    return ChatResponse(
        reply=gemini_reply,
        emotion=emotion,
        mode=mode,
        tts_audio_url=tts_url,
        debug={"state_reason": reason},
    )
3.5 ìƒíƒœ ë¨¸ì‹  / í‚¤ì›Œë“œ ê¸°ë°˜ ë¡œì§
app/core/state_machine.py

ê°„ë‹¨ í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ PoC:

â€œã…‹ã…‹, ğŸ˜†, good, awesome, ì¢‹ì•„, ì¬ë°Œâ€ â†’ happy

â€œí˜ë“¤, sad, ìš°ìš¸, ë§‰íŒ, ì•ˆë¼, ë‹µë‹µâ€ â†’ sad

ê·¸ ì™¸ â†’ base

ë§í•˜ëŠ” ìƒíƒœ(talking)ëŠ”:

í”„ë¡ íŠ¸ì—ì„œ ì‘ë‹µ ì¬ìƒ ì¤‘ì¼ ë•Œ mode='talking'

TTS ëë‚˜ë©´ mode='idle'ë¡œ ëŒì•„ê°€ê²Œ í”„ë¡ íŠ¸ì—ì„œ ì²˜ë¦¬
â†’ ë°±ì—”ë“œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ emotionë§Œ ê²°ì •í•´ë„ ë¨

python
ì½”ë“œ ë³µì‚¬
def decide_state(user_message: str, model_reply: str, current_emotion: str):
    text = (user_message + " " + model_reply).lower()
    reason = ""

    happy_keywords = ["good", "great", "awesome", "ì¬ë°Œ", "ì¢‹ì•„", "ã…‹ã…‹", "í–‰ë³µ"]
    sad_keywords = ["sad", "í˜ë“¤", "ìš°ìš¸", "ë§‰íŒ", "ë‹µë‹µ", "ìŠ¬í”„", "ë¶ˆì•ˆ"]

    emotion = "base"

    if any(k in text for k in happy_keywords):
        emotion = "happy"
        reason = "Detected happy-related keywords."
    elif any(k in text for k in sad_keywords):
        emotion = "sad"
        reason = "Detected sad-related keywords."
    else:
        emotion = "base"
        reason = "No strong emotional keywords found."

    # modeëŠ” í”„ë¡ íŠ¸ì—ì„œ TTS ì¬ìƒ ì—¬ë¶€ë¡œ ì»¨íŠ¸ë¡¤í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” idleë¡œ ë°˜í™˜
    mode = "idle"

    return emotion, mode, reason
4. í”„ë¡ íŠ¸â€“ë°± í†µì‹  ê·œì•½ (Cursorì—ì„œ ì°¸ê³ ìš©)
4.1 í”„ë¡ íŠ¸ apiClient
ts
ì½”ë“œ ë³µì‚¬
// src/lib/apiClient.ts
import { Emotion, Mode } from './emotionMapping';

export type ChatRequest = {
  session_id?: string;
  user_message: string;
  current_emotion: Emotion;
  current_mode: Mode;
};

export type ChatResponse = {
  reply: string;
  emotion: Emotion;
  mode: Mode;
  tts_audio_url?: string | null;
  debug?: Record<string, unknown>;
};

const BASE_URL = process.env.NEXT_PUBLIC_BACKEND_URL || 'http://localhost:8000';

export async function sendChat(req: ChatRequest): Promise<ChatResponse> {
  const res = await fetch(`${BASE_URL}/api/chat`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(req),
  });

  if (!res.ok) {
    throw new Error('Chat API Error');
  }

  return res.json();
}
5. êµ¬í˜„ ë‹¨ê³„ ì²´í¬ë¦¬ìŠ¤íŠ¸ (Cursor ì‘ì—… ìˆœì„œ ê°€ì´ë“œ)
Step 1 â€“ í”„ë¡œì íŠ¸ ìŠ¤ìºí´ë“œ
frontend/ì— Next.js + TS + Tailwind ì´ˆê¸°í™”

backend/ì— FastAPI ì´ˆê¸° í”„ë¡œì íŠ¸ ìƒì„±

CORS ì„¤ì • (í”„ë¡ íŠ¸ ë„ë©”ì¸ í—ˆìš©)

Step 2 â€“ Veo2 ì—ì…‹ í†µí•© (Epic 2 ì—°ê³„)
public/videos/ì— Veo2 ê²°ê³¼ë¬¼ 6ê°œ(mp4) ë°°ì¹˜

emotionMapping.tsì— ìƒíƒœâ†’ì˜ìƒ ë§¤í•‘ ì •ì˜

<VideoAvatar> ì»´í¬ë„ŒíŠ¸ë¡œ ìƒíƒœì— ë”°ë¼ ì˜ìƒ ë³€ê²½ ì˜ ë˜ëŠ”ì§€ í™•ì¸

Step 3 â€“ í…ìŠ¤íŠ¸ ì±„íŒ… + Gemini ì—°ë™ (Epic 3)
ChatPanel + useChatë¡œ í…ìŠ¤íŠ¸ ì±„íŒ… UI ì œì‘

FastAPI /api/chat + gemini_client ì‘ì„± (ì‹¤ì œ Gemini í˜¸ì¶œ or Mock)

ì‘ë‹µì˜ emotionì— ë”°ë¼ VideoAvatar ìƒíƒœ ë³€ê²½

í”„ë¡ íŠ¸ì—ì„œ mode:

ìœ ì € ì…ë ¥ ì§í›„ â†’ Companion â€œìƒê° ì¤‘â€ â†’ ì ê¹ base_idle

ì‘ë‹µ ë„ì°© + TTS ì¬ìƒ ì‹œì‘ â†’ *_talking

TTS ì¢…ë£Œ í›„ â†’ *_idle

Step 4 â€“ ìŒì„±(STT/TTS) ê¸°ëŠ¥ ì¶”ê°€ (Epic 4)
<MicButton>ì—ì„œ ë…¹ìŒ â†’ /api/sttë¡œ ì „ì†¡ â†’ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

/api/chatì—ì„œ tts_audio_url ë¦¬í„´

<AudioPlayer>ì—ì„œ URL ê¸°ë°˜ ì˜¤ë””ì˜¤ ì¬ìƒ 